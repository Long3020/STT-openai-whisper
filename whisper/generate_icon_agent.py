import pysubs2
import google.generativeai as genai
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
import pysubs2
import json
import re

# =======================
# ‚öôÔ∏è Kh·ªüi t·∫°o c·∫•u h√¨nh
# =======================

API_KEY = "AIzaSyAIE2iQ4VHZqR5chx_i09pZ24KpODgKEH0"  
SUBTITLE_FILE = "test3.ass"
COLLECTION_NAME = "emoji"
OUTPUT_FILTER_FILE = "emoji_filters.txt"

# =======================
# üöÄ Kh·ªüi t·∫°o Gemini, Qdrant, Model
# =======================

genai.configure(api_key=API_KEY)
model_gemini = genai.GenerativeModel('gemini-2.0-flash')
model_embed = SentenceTransformer('all-MiniLM-L6-v2')
client = QdrantClient(host="localhost", port=6333)

# =======================
# üî† H√†m x·ª≠ l√Ω ph·ª• ƒë·ªÅ
# =======================

def ask_gemini_to_extract_subs(text):
    prompt = f"""
        You are given the text content of an .ass subtitle file. Your task is to extract and output only the subtitle text lines in the correct order, ignoring all timing, styling, formatting, and metadata information.

        Input example:
        [Script Info]
        ; Script generated by pysubs2
        ; https://pypi.python.org/pypi/pysubs2
        WrapStyle: 0
        ScaledBorderAndShadow: yes
        Collisions: Normal
        ScriptType: v4.00+

        [V4+ Styles]
        Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
        Style: Default,Arial,24,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

        [Events]
        Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
        Dialogue: 0,0:00:00.00,0:00:00.16,Default,,0,0,0,,This
        Dialogue: 0,0:00:00.16,0:00:00.26,Default,,0,0,0,,is
        Dialogue: 0,0:00:00.26,0:00:00.40,Default,,0,0,0,,your
        Dialogue: 0,0:00:00.40,0:00:00.62,Default,,0,0,0,,warning
        Dialogue: 0,0:00:00.62,0:00:00.82,Default,,0,0,0,,to
        Dialogue: 0,0:00:00.82,0:00:01.16,Default,,0,0,0,,never
        Dialogue: 0,0:00:01.16,0:00:01.34,Default,,0,0,0,,be
        Dialogue: 0,0:00:01.34,0:00:01.58,Default,,0,0,0,,friends
        Dialogue: 0,0:00:01.58,0:00:01.74,Default,,0,0,0,,with
        Dialogue: 0,0:00:01.74,0:00:01.84,Default,,0,0,0,,a
        Dialogue: 0,0:00:01.84,0:00:02.20,Default,,0,0,0,,bilingual
        Dialogue: 0,0:00:02.20,0:00:02.58,Default,,0,0,0,,person
        Dialogue: 0,0:00:02.58,0:00:02.82,Default,,0,0,0,,because
        Dialogue: 0,0:00:02.82,0:00:02.98,Default,,0,0,0,,I
        Dialogue: 0,0:00:02.98,0:00:03.06,Default,,0,0,0,,have
        Dialogue: 0,0:00:03.06,0:00:03.16,Default,,0,0,0,,a
        Dialogue: 0,0:00:03.16,0:00:03.32,Default,,0,0,0,,friend
        Dialogue: 0,0:00:03.32,0:00:03.46,Default,,0,0,0,,that
        Dialogue: 0,0:00:03.46,0:00:03.64,Default,,0,0,0,,speaks
        Dialogue: 0,0:00:03.64,0:00:04.06,Default,,0,0,0,,English
        Dialogue: 0,0:00:04.06,0:00:04.44,Default,,0,0,0,,and
        Dialogue: 0,0:00:04.44,0:00:04.76,Default,,0,0,0,,Spanish
        Dialogue: 0,0:00:04.76,0:00:05.08,Default,,0,0,0,,But
        Dialogue: 0,0:00:05.08,0:00:05.24,Default,,0,0,0,,his
        Dialogue: 0,0:00:05.24,0:00:05.48,Default,,0,0,0,,parents
        Dialogue: 0,0:00:05.48,0:00:05.62,Default,,0,0,0,,are
        Dialogue: 0,0:00:05.62,0:00:05.78,Default,,0,0,0,,from
        Dialogue: 0,0:00:05.78,0:00:06.04,Default,,0,0,0,,Mexico,
        Dialogue: 0,0:00:06.04,0:00:06.46,Default,,0,0,0,,so
        Dialogue: 0,0:00:06.46,0:00:06.58,Default,,0,0,0,,they
        Dialogue: 0,0:00:06.58,0:00:06.70,Default,,0,0,0,,don't
        Dialogue: 0,0:00:06.70,0:00:06.86,Default,,0,0,0,,know
        Dialogue: 0,0:00:06.86,0:00:07.08,Default,,0,0,0,,any
        Dialogue: 0,0:00:07.08,0:00:07.40,Default,,0,0,0,,English
        Dialogue: 0,0:00:07.40,0:00:07.66,Default,,0,0,0,,So
        Dialogue: 0,0:00:07.66,0:00:07.78,Default,,0,0,0,,when
        Dialogue: 0,0:00:07.78,0:00:07.90,Default,,0,0,0,,I
        Dialogue: 0,0:00:07.90,0:00:08.08,Default,,0,0,0,,met
        Dialogue: 0,0:00:08.08,0:00:08.22,Default,,0,0,0,,them
        Dialogue: 0,0:00:08.22,0:00:08.34,Default,,0,0,0,,for
        Dialogue: 0,0:00:08.34,0:00:08.46,Default,,0,0,0,,the
        Dialogue: 0,0:00:08.46,0:00:08.62,Default,,0,0,0,,first
        Dialogue: 0,0:00:08.62,0:00:08.88,Default,,0,0,0,,time
        Dialogue: 0,0:00:08.88,0:00:09.14,Default,,0,0,0,,it
        Dialogue: 0,0:00:09.14,0:00:09.30,Default,,0,0,0,,was
        Dialogue: 0,0:00:09.30,0:00:09.44,Default,,0,0,0,,a
        Dialogue: 0,0:00:09.44,0:00:09.62,Default,,0,0,0,,nightmare
        Dialogue: 0,0:00:09.62,0:00:10.02,Default,,0,0,0,,because
        Dialogue: 0,0:00:10.02,0:00:10.28,Default,,0,0,0,,my
        Dialogue: 0,0:00:10.28,0:00:10.56,Default,,0,0,0,,friend
        Dialogue: 0,0:00:10.56,0:00:10.78,Default,,0,0,0,,likes
        Dialogue: 0,0:00:10.78,0:00:10.92,Default,,0,0,0,,to
        Dialogue: 0,0:00:10.92,0:00:11.16,Default,,0,0,0,,troll
        Dialogue: 0,0:00:11.16,0:00:11.32,Default,,0,0,0,,a
        Dialogue: 0,0:00:11.32,0:00:11.48,Default,,0,0,0,,lot
        Dialogue: 0,0:00:11.48,0:00:11.60,Default,,0,0,0,,But
        Dialogue: 0,0:00:11.60,0:00:11.74,Default,,0,0,0,,he
        Dialogue: 0,0:00:11.74,0:00:11.84,Default,,0,0,0,,had
        Dialogue: 0,0:00:11.84,0:00:11.90,Default,,0,0,0,,to
        Dialogue: 0,0:00:11.90,0:00:11.96,Default,,0,0,0,,be
        Dialogue: 0,0:00:11.96,0:00:12.08,Default,,0,0,0,,the
        Dialogue: 0,0:00:12.08,0:00:12.46,Default,,0,0,0,,translator
        Dialogue: 0,0:00:12.46,0:00:12.70,Default,,0,0,0,,for
        Dialogue: 0,0:00:12.70,0:00:12.82,Default,,0,0,0,,me
        Dialogue: 0,0:00:12.82,0:00:12.92,Default,,0,0,0,,to
        Dialogue: 0,0:00:12.92,0:00:13.26,Default,,0,0,0,,communicate
        Dialogue: 0,0:00:13.26,0:00:13.48,Default,,0,0,0,,with
        Dialogue: 0,0:00:13.48,0:00:13.62,Default,,0,0,0,,his
        Dialogue: 0,0:00:13.62,0:00:13.92,Default,,0,0,0,,parents
        Dialogue: 0,0:00:13.92,0:00:14.26,Default,,0,0,0,,since
        Dialogue: 0,0:00:14.26,0:00:14.42,Default,,0,0,0,,he
        Dialogue: 0,0:00:14.42,0:00:14.50,Default,,0,0,0,,was
        Dialogue: 0,0:00:14.50,0:00:14.60,Default,,0,0,0,,the
        Dialogue: 0,0:00:14.60,0:00:14.82,Default,,0,0,0,,only
        Dialogue: 0,0:00:14.82,0:00:15.00,Default,,0,0,0,,one
        Dialogue: 0,0:00:15.00,0:00:15.14,Default,,0,0,0,,who
        Dialogue: 0,0:00:15.14,0:00:15.22,Default,,0,0,0,,knew
        Dialogue: 0,0:00:15.22,0:00:15.48,Default,,0,0,0,,both
        Dialogue: 0,0:00:15.48,0:00:15.86,Default,,0,0,0,,languages
        Dialogue: 0,0:00:15.86,0:00:16.06,Default,,0,0,0,,So
        Dialogue: 0,0:00:16.06,0:00:16.22,Default,,0,0,0,,when
        Dialogue: 0,0:00:16.22,0:00:16.34,Default,,0,0,0,,we
        Dialogue: 0,0:00:16.34,0:00:16.72,Default,,0,0,0,,talked
        Dialogue: 0,0:00:16.72,0:00:17.32,Default,,0,0,0,,he
        Dialogue: 0,0:00:17.32,0:00:17.54,Default,,0,0,0,,would
        Dialogue: 0,0:00:17.54,0:00:17.98,Default,,0,0,0,,purposely
        Dialogue: 0,0:00:17.98,0:00:18.66,Default,,0,0,0,,mistranslate
        Dialogue: 0,0:00:18.66,0:00:18.80,Default,,0,0,0,,what
        Dialogue: 0,0:00:18.80,0:00:18.92,Default,,0,0,0,,I
        Dialogue: 0,0:00:18.92,0:00:19.14,Default,,0,0,0,,said
        Dialogue: 0,0:00:19.14,0:00:19.28,Default,,0,0,0,,to
        Dialogue: 0,0:00:19.28,0:00:19.40,Default,,0,0,0,,his
        Dialogue: 0,0:00:19.40,0:00:19.66,Default,,0,0,0,,parents
        Dialogue: 0,0:00:19.66,0:00:19.90,Default,,0,0,0,,because
        Dialogue: 0,0:00:19.90,0:00:20.00,Default,,0,0,0,,he
        Dialogue: 0,0:00:20.00,0:00:20.14,Default,,0,0,0,,thought
        Dialogue: 0,0:00:20.14,0:00:20.22,Default,,0,0,0,,it
        Dialogue: 0,0:00:20.22,0:00:20.32,Default,,0,0,0,,was
        Dialogue: 0,0:00:20.32,0:00:20.52,Default,,0,0,0,,funny
        Dialogue: 0,0:00:20.52,0:00:20.72,Default,,0,0,0,,Like
        Dialogue: 0,0:00:20.72,0:00:20.82,Default,,0,0,0,,I
        Dialogue: 0,0:00:20.82,0:00:20.94,Default,,0,0,0,,was
        Dialogue: 0,0:00:20.94,0:00:21.02,Default,,0,0,0,,in
        Dialogue: 0,0:00:21.02,0:00:21.12,Default,,0,0,0,,the
        Dialogue: 0,0:00:21.12,0:00:21.28,Default,,0,0,0,,car
        Dialogue: 0,0:00:21.28,0:00:21.42,Default,,0,0,0,,with
        Dialogue: 0,0:00:21.42,0:00:21.56,Default,,0,0,0,,his
        Dialogue: 0,0:00:21.56,0:00:21.78,Default,,0,0,0,,whole
        Dialogue: 0,0:00:21.78,0:00:22.14,Default,,0,0,0,,family
        Dialogue: 0,0:00:22.14,0:00:22.40,Default,,0,0,0,,and
        Dialogue: 0,0:00:22.40,0:00:22.52,Default,,0,0,0,,his
        Dialogue: 0,0:00:22.52,0:00:22.66,Default,,0,0,0,,mom
        Dialogue: 0,0:00:22.66,0:00:23.00,Default,,0,0,0,,asked
        Dialogue: 0,0:00:23.00,0:00:23.12,Default,,0,0,0,,what
        Dialogue: 0,0:00:23.12,0:00:23.30,Default,,0,0,0,,type
        Dialogue: 0,0:00:23.30,0:00:23.44,Default,,0,0,0,,of
        Dialogue: 0,0:00:23.44,0:00:23.64,Default,,0,0,0,,music
        Dialogue: 0,0:00:23.64,0:00:23.84,Default,,0,0,0,,I
        Dialogue: 0,0:00:23.84,0:00:24.06,Default,,0,0,0,,listened
        Dialogue: 0,0:00:24.06,0:00:24.22,Default,,0,0,0,,to
        Dialogue: 0,0:00:24.22,0:00:24.38,Default,,0,0,0,,So
        Dialogue: 0,0:00:24.38,0:00:24.50,Default,,0,0,0,,I
        Dialogue: 0,0:00:24.50,0:00:24.72,Default,,0,0,0,,told
        Dialogue: 0,0:00:24.72,0:00:24.84,Default,,0,0,0,,her
        Dialogue: 0,0:00:24.84,0:00:24.96,Default,,0,0,0,,that
        Dialogue: 0,0:00:24.96,0:00:25.04,Default,,0,0,0,,I
        Dialogue: 0,0:00:25.04,0:00:25.30,Default,,0,0,0,,mostly
        Dialogue: 0,0:00:25.30,0:00:25.64,Default,,0,0,0,,listened
        Dialogue: 0,0:00:25.64,0:00:25.78,Default,,0,0,0,,to
        Dialogue: 0,0:00:25.78,0:00:26.02,Default,,0,0,0,,rap
        Dialogue: 0,0:00:26.02,0:00:26.20,Default,,0,0,0,,and
        Dialogue: 0,0:00:26.20,0:00:26.36,Default,,0,0,0,,R
        Dialogue: 0,0:00:26.36,0:00:26.58,Default,,0,0,0,,&B
        Dialogue: 0,0:00:26.58,0:00:26.72,Default,,0,0,0,,But
        Dialogue: 0,0:00:26.72,0:00:26.84,Default,,0,0,0,,when
        Dialogue: 0,0:00:26.84,0:00:26.96,Default,,0,0,0,,I
        Dialogue: 0,0:00:26.96,0:00:27.18,Default,,0,0,0,,said
        Dialogue: 0,0:00:27.18,0:00:27.42,Default,,0,0,0,,this
        Dialogue: 0,0:00:27.42,0:00:27.90,Default,,0,0,0,,my
        Dialogue: 0,0:00:27.90,0:00:28.18,Default,,0,0,0,,friend
        Dialogue: 0,0:00:28.18,0:00:28.46,Default,,0,0,0,,starts
        Dialogue: 0,0:00:28.46,0:00:28.88,Default,,0,0,0,,chuckling
        Dialogue: 0,0:00:28.88,0:00:29.10,Default,,0,0,0,,when
        Dialogue: 0,0:00:29.10,0:00:29.26,Default,,0,0,0,,he's
        Dialogue: 0,0:00:29.26,0:00:29.38,Default,,0,0,0,,trying
        Dialogue: 0,0:00:29.38,0:00:29.50,Default,,0,0,0,,to
        Dialogue: 0,0:00:29.50,0:00:29.68,Default,,0,0,0,,relay
        Dialogue: 0,0:00:29.68,0:00:29.84,Default,,0,0,0,,the
        Dialogue: 0,0:00:29.84,0:00:30.06,Default,,0,0,0,,message
        Dialogue: 0,0:00:30.06,0:00:30.30,Default,,0,0,0,,to
        Dialogue: 0,0:00:30.30,0:00:30.42,Default,,0,0,0,,his
        Dialogue: 0,0:00:30.42,0:00:30.68,Default,,0,0,0,,parents
        Dialogue: 0,0:00:30.68,0:00:30.92,Default,,0,0,0,,But
        Dialogue: 0,0:00:30.92,0:00:31.18,Default,,0,0,0,,then
        Dialogue: 0,0:00:31.18,0:00:31.32,Default,,0,0,0,,I
        Dialogue: 0,0:00:31.32,0:00:31.72,Default,,0,0,0,,understood
        Dialogue: 0,0:00:31.72,0:00:32.02,Default,,0,0,0,,it
        Dialogue: 0,0:00:32.02,0:00:32.16,Default,,0,0,0,,because
        Dialogue: 0,0:00:32.16,0:00:32.30,Default,,0,0,0,,when
        Dialogue: 0,0:00:32.30,0:00:32.40,Default,,0,0,0,,he
        Dialogue: 0,0:00:32.40,0:00:32.60,Default,,0,0,0,,spoke
        Dialogue: 0,0:00:32.60,0:00:32.92,Default,,0,0,0,,Spanish
        Dialogue: 0,0:00:32.92,0:00:33.20,Default,,0,0,0,,back
        Dialogue: 0,0:00:33.20,0:00:33.36,Default,,0,0,0,,to
        Dialogue: 0,0:00:33.36,0:00:33.46,Default,,0,0,0,,his
        Dialogue: 0,0:00:33.46,0:00:33.72,Default,,0,0,0,,parents
        Dialogue: 0,0:00:33.72,0:00:34.26,Default,,0,0,0,,I
        Dialogue: 0,0:00:34.26,0:00:34.42,Default,,0,0,0,,only
        Dialogue: 0,0:00:34.42,0:00:34.84,Default,,0,0,0,,recognized
        Dialogue: 0,0:00:34.84,0:00:35.30,Default,,0,0,0,,one
        Dialogue: 0,0:00:35.30,0:00:35.40,Default,,0,0,0,,of
        Dialogue: 0,0:00:35.40,0:00:35.48,Default,,0,0,0,,the
        Dialogue: 0,0:00:35.48,0:00:35.68,Default,,0,0,0,,words
        Dialogue: 0,0:00:35.68,0:00:35.86,Default,,0,0,0,,he
        Dialogue: 0,0:00:35.86,0:00:36.16,Default,,0,0,0,,said
        Dialogue: 0,0:00:36.16,0:00:36.58,Default,,0,0,0,,which
        Dialogue: 0,0:00:36.58,0:00:36.78,Default,,0,0,0,,was
        Dialogue: 0,0:00:36.78,0:00:37.28,Default,,0,0,0,,diddy
        Dialogue: 0,0:00:37.28,0:00:37.46,Default,,0,0,0,,He
        Dialogue: 0,0:00:37.46,0:00:37.62,Default,,0,0,0,,told
        Dialogue: 0,0:00:37.62,0:00:37.76,Default,,0,0,0,,his
        Dialogue: 0,0:00:37.76,0:00:38.02,Default,,0,0,0,,parents
        Dialogue: 0,0:00:38.02,0:00:38.20,Default,,0,0,0,,that
        Dialogue: 0,0:00:38.20,0:00:38.36,Default,,0,0,0,,I
        Dialogue: 0,0:00:38.36,0:00:38.50,Default,,0,0,0,,like
        Dialogue: 0,0:00:38.50,0:00:38.62,Default,,0,0,0,,to
        Dialogue: 0,0:00:38.62,0:00:38.82,Default,,0,0,0,,listen
        Dialogue: 0,0:00:38.82,0:00:38.98,Default,,0,0,0,,to
        Dialogue: 0,0:00:38.98,0:00:39.24,Default,,0,0,0,,diddy
        Dialogue: 0,0:00:39.24,0:00:39.38,Default,,0,0,0,,So
        Dialogue: 0,0:00:39.38,0:00:39.54,Default,,0,0,0,,from
        Dialogue: 0,0:00:39.54,0:00:39.68,Default,,0,0,0,,there
        Dialogue: 0,0:00:39.68,0:00:39.80,Default,,0,0,0,,on
        Dialogue: 0,0:00:39.80,0:00:39.96,Default,,0,0,0,,out
        Dialogue: 0,0:00:39.96,0:00:40.42,Default,,0,0,0,,I
        Dialogue: 0,0:00:40.42,0:00:40.58,Default,,0,0,0,,just
        Dialogue: 0,0:00:40.58,0:00:40.78,Default,,0,0,0,,started
        Dialogue: 0,0:00:40.78,0:00:40.98,Default,,0,0,0,,using
        Dialogue: 0,0:00:40.98,0:00:41.18,Default,,0,0,0,,my
        Dialogue: 0,0:00:41.18,0:00:41.38,Default,,0,0,0,,phone
        Dialogue: 0,0:00:41.38,0:00:41.50,Default,,0,0,0,,to
        Dialogue: 0,0:00:41.50,0:00:41.76,Default,,0,0,0,,translate
        Dialogue: 0,0:00:41.76,0:00:41.94,Default,,0,0,0,,what
        Dialogue: 0,0:00:41.94,0:00:42.08,Default,,0,0,0,,they
        Dialogue: 0,0:00:42.08,0:00:42.26,Default,,0,0,0,,said


        Please output only the subtitle text content concatenated in order, separated by spaces. Do NOT include any timestamps, styling, or other metadata.

        Output example:
        This is your warning to never be friends with a bilingual person because I have a friend who speaks English and Spanish. 
        But his parents are from Mexico, so they don‚Äôt know any English. So when I met them for the first time, it was a nightmare 
        because my friend likes to troll a lot. But he had to be the translator for me to communicate with his parents since he was 
        the only one who knew both languages. So when we talked, he would purposely mistranslate what I said to his parents because 
        he thought it was funny. Like I was in the car with his whole family and his mom asked what type of music I listened to. So I 
        told her that I mostly listened to rap and R&B. But when I said this, my friend starts chuckling when he's trying to relay the 
        message to his parents. But then I understood it because when he spoke Spanish back to his parents, I only recognized one of the
        words he said, which was "diddy." He told his parents that I like to listen to Diddy. So from there on out, I just started 
        using my phone to translate what they said.

        Now process the following subtitle text:

        \"\"\"
        {text}
        \"\"\"

    """
    response = model_gemini.generate_content(prompt)
    phrases = [line.strip() for line in response.text.splitlines() if line.strip()]
    return " ".join(phrases)

def ask_gemini_to_highlight_text(text):
    prompt = f"""
        You are an intelligent AI Agent specialized in subtitle enhancement and visual communication.

        ## Objective:
        Analyze the provided subtitle text and decide which individual words or short phrases should be visually highlighted to increase viewer comprehension and engagement.

        ## Guidelines:
        - Focus on semantically important words or short phrases conveying key actions, emotions, or emphasis.
        - You may include multi-word phrases like "signed up" or "baby steps".
        - However, in your output, **split all multi-word phrases into individual words**.
        - Avoid generic filler words (e.g., "the", "a", "you") and pronouns unless strongly emphasized.

        ## Output format:
        Return a Python list of strings ONLY.
        Your entire output should be exactly and only this Python list, for example:

        ["signed", "up", "gym", "baby", "steps", "walked", "past", "cardio"]

        Do NOT add any extra characters, quotes, or markdown code blocks.
        Do NOT return a string containing a list, return the list itself.
        No explanation or other text.
        
        Now process the following subtitle text:

        \"\"\"
        {text}
        \"\"\"
        """

    response = model_gemini.generate_content(prompt)
    phrases = [line.strip() for line in response.text.splitlines() if line.strip()]
    highlight_words = phrases[0]
    highlight_words = json.loads(highlight_words)
    return highlight_words



def ask_gemini_to_segment_text(text):
    prompt = f"""
        You're an intelligent AI Agent specialized in analyzing subtitles and suggesting expressive emoji representations.

        ## Objective:
        Analyze the following subtitle text and identify **individual words or short phrases** that are meaningful and can be visually represented with emojis. Your goal is to enhance viewer understanding and engagement by converting text into appropriate emoji associations.

        ## Contextual Intelligence:
        - Reconstruct phrases if the subtitle is broken word-by-word.
        - Use your understanding of natural language and context to group words meaningfully.
        - Extract phrases that convey concrete concepts, emotions, feelings, or recognizable actions.
        - Include emotionally expressive adjectives and adverbs (e.g., "nice", "happy", "terrible") because they influence the tone and viewer reaction.

        ## Emoji Mapping (STRICT GUIDELINES):
        - For each phrase, return a list of emoji **names** (e.g., "rocket", "calendar", "heart_on_fire").
        - **Use only ONE emoji if it clearly conveys the idea.**
        - Use TWO only if the phrase has multiple **distinct and non-overlapping concepts** (e.g., "baby steps" ‚Üí ["baby", "footprints"]).
        - **Do NOT use emoji variants, synonyms, or near-duplicates.** Pick the **most representative** emoji only.
        - Include time-related emojis (like "calendar", "clock") only when the time is central to the message or emotional tone.
        - Avoid combining multiple emojis with nearly identical meanings (e.g., "muscle" + "gym" ‚Üí keep only "weight_lifter").
        - Do NOT use emoji characters ‚Äî return emoji **names** only.

        ## Output format:
        Return a **Python dictionary** in the format:
        - Keys = selected phrases (as strings)
        - Values = list of 1‚Äì2 emoji names

        ### Example input:
        I finally signed up for the gym today. Baby steps, but I walked past the cardio area. It was a nice day.

        ### Example output:
        {{
        "signed up": ["memo"],
        "gym": ["weight_lifter"],
        "today": ["calendar"],
        "walked past": ["walking"],
        "cardio": ["heart"],
        "baby steps": ["baby", "footprints"],
        "nice": ["smiling_face_with_smiling_eyes"]
        }}

        Now process the following subtitle text:

        \"\"\"
        {text}
        \"\"\"
        """

    response = model_gemini.generate_content(prompt)
    phrases = [line.strip() for line in response.text.splitlines() if line.strip()]
    return phrases

def convert_to_dict(phrases: list[str]) -> dict:
    # B·ªè 2 d√≤ng ƒë·∫ßu v√† cu·ªëi (n·∫øu ƒë√∫ng ƒë·ªãnh d·∫°ng)
    # Ho·∫∑c lo·∫°i b·ªè d√≤ng ch·ª©a ``` n·∫øu c√≥
    filtered_lines = [line for line in phrases if not line.strip().startswith('```')]
    
    # Gh√©p c√°c d√≤ng l·∫°i th√†nh chu·ªói
    dict_str = "\n".join(filtered_lines)
    
    return json.loads(dict_str)

def search_nearest_emoji(phrase):
    vector = model_embed.encode(phrase).tolist()
    results = client.query_points(
        collection_name=COLLECTION_NAME,
        query=vector,
        limit=1,
        with_payload=True
    )
    # Ki·ªÉm tra v√† l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n t·ª´ k·∫øt qu·∫£
    if results and results.points:
        point = results.points[0]
        desc = point.payload.get("desc", "N/A")
        path = point.payload.get("path", "N/A")
        return desc, path

    return "", ""

# =======================
# üé¨ X·ª≠ l√Ω subtitle ‚Üí emoji
# =======================

subs = pysubs2.load(SUBTITLE_FILE)
full_text = " ".join(line.text for line in subs)

full_text = ask_gemini_to_extract_subs(full_text)
print(full_text)

phrases = ask_gemini_to_segment_text(full_text)
phrases = convert_to_dict(phrases)
print("\nüîπ Meaningful phrases:")
for phrase, emojis in phrases.items():
    print(f"{phrase} ‚Üí {emojis}")

emoji_overlays = []
current_pos = 0

prev_end_time = 0.0  # Ghi nh·ªõ th·ªùi gian k·∫øt th√∫c tr∆∞·ªõc ƒë√≥

for i, (phrase, emojis) in enumerate(phrases.items()):    
    start_idx = full_text.find(phrase, current_pos)
    if start_idx == -1:
        continue
    end_idx = start_idx + len(phrase)

    start_time = None
    end_time = None
    acc_len = 0
    phrase_start_found = False

    for line in subs:
        line_text = line.text
        line_len = len(line_text)
        if not phrase_start_found and acc_len + line_len >= start_idx:
            start_time = line.start / 1000
            phrase_start_found = True
        if phrase_start_found and acc_len + line_len >= end_idx:
            end_time = line.end / 1000
            break
        acc_len += line_len + 1

    # X·ª≠ l√Ω th·ªùi gian kh√¥ng t√¨m ƒë∆∞·ª£c
    if start_time is None:
        start_time = prev_end_time
    if end_time is None or end_time < start_time:
        end_time = start_time + 1.0

    # ƒê·∫£m b·∫£o kh√¥ng l√πi th·ªùi gian so v·ªõi ƒëo·∫°n tr∆∞·ªõc
    if start_time < prev_end_time:
        delta = prev_end_time - start_time
        start_time += delta
        end_time += delta

    prev_end_time = end_time  # C·∫≠p nh·∫≠t cho phrase ti·∫øp theo

    for emoji in emojis:
        desc, path = search_nearest_emoji(emoji)
        print(f"'{phrase}' - '{emoji}' ‚Üí ({desc}) [{start_time:.2f}s - {end_time:.2f}s]")
        emoji_overlays.append((path, start_time, end_time))

highlight_words = ask_gemini_to_highlight_text(full_text)
print(highlight_words)
for word in highlight_words:
    print(word)
highlight_color = r"{\c&H00C0FF&}"  # V√†ng
animation = r"{\fscx50\fscy50\t(0,050,\fscx100\fscy100)\bord4\shad2}"
for line in subs:
    print(line)
    print(line.text)
     # Lo·∫°i b·ªè d·∫•u c√¢u, ch·ªâ gi·ªØ ch·ªØ v√† s·ªë, c√°ch nhau b·∫±ng d·∫•u c√°ch
    cleaned_text = ' '.join(re.findall(r'\b\w+\b', line.text))
    print(cleaned_text)
    # G·∫Øn tag v√†o ƒë·∫ßu text
    if cleaned_text.strip() in highlight_words:
        line.text = f"{highlight_color}{line.text}"
    line.text = f"{animation}{line.text}"

subs.save(SUBTITLE_FILE)

# =======================
# üéûÔ∏è Ghi file FFmpeg filter
# =======================

# Gi·∫£ s·ª≠ emoji_overlays = [(path, start, end), ...]

# H√†m t√¨m nh·ªØng emoji overlap v·ªõi emoji i
def find_overlaps(i, overlays):
    start_i = overlays[i][1]
    end_i = overlays[i][2]
    overlaps = []
    for j, (path, start, end) in enumerate(overlays):
        # Ki·ªÉm tra overlap th·ªùi gian
        if not (end <= start_i or end_i <= start):
            overlaps.append(j)
    return overlaps

with open(OUTPUT_FILTER_FILE, "w", encoding="utf-8") as f:
    filters = []
    slide_duration = 0.05
    shadow_offset_x = 5
    shadow_offset_y = 5
    blur_sigma = 5
    spacing = 150

    for i, (img_path, start, end) in enumerate(emoji_overlays):
        input_stream = f"[{i+1}:v]"
        base_stream = "[0:v]" if i == 0 else f"[tmp{i}]"
        output_stream = f"[tmp{i+1}]"
        enable = f"between(t\\,{start:.2f}\\,{end:.2f})"

        overlaps = find_overlaps(i, emoji_overlays)
        idx_in_group = overlaps.index(i)
        total_in_group = len(overlaps)

        x_center = f"(main_w-overlay_w)/2 + ({idx_in_group} - {(total_in_group - 1)/2})*{spacing}"
        y_center = "(main_h-overlay_h)/2 - 100"

        direction = i % 4  # 0: left, 1: top, 2: right, 3: bottom

        # Slide OUT when ending
        if direction == 0:  # left
            slide_x_expr = (
                f"if(between(t\\,{end - slide_duration:.2f}\\,{end:.2f}),"
                f"{x_center} + (0 - {x_center})*((t-{end - slide_duration:.2f})/{slide_duration:.2f}),"
                f"{x_center})"
            )
            slide_y_expr = y_center
        elif direction == 1:  # top
            slide_x_expr = x_center
            slide_y_expr = (
                f"if(between(t\\,{end - slide_duration:.2f}\\,{end:.2f}),"
                f"{y_center} + (0 - {y_center})*((t-{end - slide_duration:.2f})/{slide_duration:.2f}),"
                f"{y_center})"
            )
        elif direction == 2:  # right
            slide_x_expr = (
                f"if(between(t\\,{end - slide_duration:.2f}\\,{end:.2f}),"
                f"{x_center} + (main_w - {x_center})*((t-{end - slide_duration:.2f})/{slide_duration:.2f}),"
                f"{x_center})"
            )
            slide_y_expr = y_center
        else:  # bottom
            slide_x_expr = x_center
            slide_y_expr = (
                f"if(between(t\\,{end - slide_duration:.2f}\\,{end:.2f}),"
                f"{y_center} + (main_h - {y_center})*((t-{end - slide_duration:.2f})/{slide_duration:.2f}),"
                f"{y_center})"
            )

        filters.append(
            f"{input_stream}format=rgba,split=2[base{i}][shadow{i}];"
            f"[shadow{i}]lutrgb='r=0:g=0:b=0',gblur=sigma={blur_sigma},format=rgba[shadowblur{i}];"
            f"{base_stream}[shadowblur{i}]overlay="
            f"x='({slide_x_expr})+{shadow_offset_x}':"
            f"y='({slide_y_expr})+{shadow_offset_y}':"
            f"enable='{enable}'[withshadow{i}];"
            f"[withshadow{i}][base{i}]overlay="
            f"x='{slide_x_expr}':"
            f"y='{slide_y_expr}':"
            f"enable='{enable}'{output_stream}"
        )

    f.write(";".join(filters))

print("\n‚úÖ Emoji overlay filter saved to emoji_filters.txt")

# =======================
# üõ†Ô∏è Sinh file .bat ch·∫°y FFmpeg
# =======================

VIDEO_INPUT = "test3.mp4"
VIDEO_OUTPUT = "test_emojis3.mp4"
BAT_FILE = "run_ffmpeg.bat"

emoji_paths = [path.replace("\\", "/") for path, _, _ in emoji_overlays]

# T·∫°o danh s√°ch ƒë·∫ßu v√†o
input_args = [f"-i \"{VIDEO_INPUT}\""] + [f"-i \"{path}\"" for path in emoji_paths]

# Output stream l√† nh√£n cu·ªëi c√πng, t∆∞∆°ng ·ª©ng v·ªõi [tmpN]
final_stream = f"[tmp{len(emoji_overlays)}]"

with open(OUTPUT_FILTER_FILE, "r", encoding="utf-8") as f:
    filter_complex_content = f.read().replace('\n', ';')

ffmpeg_command = (
    "ffmpeg " +
    " ".join(input_args) + " " +
    f"-filter_complex \"{filter_complex_content}\" " +
    f"-map \"{final_stream}\" -map 0:a? " +
    f"\"{VIDEO_OUTPUT}\""
)

with open(BAT_FILE, "w", encoding="utf-8") as f:
    f.write(ffmpeg_command + "\n")

print(f"\n‚úÖ ƒê√£ ghi l·ªánh FFmpeg v√†o file: {BAT_FILE}")
print(f"üöÄ ƒêang ch·∫°y file .bat...")

import subprocess
subprocess.run(f'"{BAT_FILE}"', shell=True)

